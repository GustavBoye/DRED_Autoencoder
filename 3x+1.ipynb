{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0jJvvURudyM4VQLpEv7Ed",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavBoye/DRED_Autoencoder/blob/main/3x%2B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSA7alfnslav",
        "outputId": "09cd6891-4692-4c2b-c9de-50fbeabe9e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "\n",
        "\n",
        "def collatz_sequence(n):\n",
        "    \"\"\"Computes the Collatz sequence for a given number.\"\"\"\n",
        "    steps = 0\n",
        "    while n != 1:\n",
        "        if n % 2 == 0:\n",
        "            n //= 2\n",
        "        else:\n",
        "            n = 3 * n + 1\n",
        "        steps += 1\n",
        "    return steps\n",
        "\n",
        "def create_training_data(amount, height):\n",
        "    \"\"\"Generates training data with a mix of small and large numbers.\"\"\"\n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    for _ in range(amount):\n",
        "        num = random.randint(1, height)\n",
        "        steps = collatz_sequence(num)\n",
        "        train_x.append(num)\n",
        "        train_y.append(steps*0.00001)\n",
        "    return np.array(train_x), np.array(train_y)\n",
        "\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"Creates an improved neural network model using the Functional API.\"\"\"\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(1,))\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(32, kernel_initializer=HeNormal())(inputs)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(32, kernel_initializer=HeNormal())(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Initial dense layer\n",
        "    xb = Dense(32, kernel_initializer=HeNormal())(x)\n",
        "    xb = LayerNormalization()(xb)\n",
        "    xb = LeakyReLU(alpha=0.1)(xb)\n",
        "\n",
        "    b = x + xb\n",
        "\n",
        "    for i in range(2):\n",
        "      # Initial dense layer\n",
        "      x = Dense(32, kernel_initializer=HeNormal())(b)\n",
        "      x = LayerNormalization()(x)\n",
        "      x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "      # Initial dense layer\n",
        "      xb = Dense(32, kernel_initializer=HeNormal())(x)\n",
        "      xb = LayerNormalization()(xb)\n",
        "      xb = LeakyReLU(alpha=0.1)(xb)\n",
        "\n",
        "      b = x + xb\n",
        "\n",
        "    x = Dense(32, kernel_initializer=HeNormal())(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(1)(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def create_model2():\n",
        "    \"\"\"Creates an improved neural network model using the Functional API.\"\"\"\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(1,))\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(512, kernel_initializer=HeNormal())(inputs)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(512, kernel_initializer=HeNormal())(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(512, kernel_initializer=HeNormal())(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    xb = Dense(512, kernel_initializer=HeNormal())(x)\n",
        "    xb = BatchNormalization()(x)\n",
        "    xb = tf.keras.layers.Activation('sigmoid')(xb)\n",
        "\n",
        "    x = x + xb\n",
        "\n",
        "    x = Dense(256, kernel_initializer=HeNormal())(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(256, kernel_initializer=HeNormal())(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Initial dense layer\n",
        "    x = Dense(256, kernel_initializer=HeNormal())(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    xb = Dense(256, kernel_initializer=HeNormal())(x)\n",
        "    xb = BatchNormalization()(x)\n",
        "    xb = tf.keras.layers.Activation('sigmoid')(xb)\n",
        "\n",
        "    x = x + xb\n",
        "\n",
        "    x = Dense(64, kernel_initializer=HeNormal())(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(1)(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def train_and_predict(model, train_x, train_y, test_x, test_y):\n",
        "\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_x, train_y, epochs=1, batch_size=128, verbose=1)\n",
        "\n",
        "    # Make a prediction on the test example\n",
        "    prediction = model.predict(test_x.reshape(-1, 1), verbose=0)[0][0]\n",
        "    actual = test_y[0]\n",
        "    return prediction, actual\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Check if the model exists, if so, load it\n",
        "model_path = \"latest_model.keras\"\n",
        "if False:\n",
        "    print(\"Loading existing model...\")\n",
        "    model = load_model(model_path)\n",
        "else:\n",
        "    print(\"Creating new model...\")\n",
        "    model = create_model2()\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "    # Generate dataset of 140,000 numbers\n",
        "    train_x, train_y = create_training_data(250000, 1000000000000)\n",
        "\n",
        "    # Generate a new test example (not in the training data)\n",
        "    test_x = random.randint(1, 1000000000000)\n",
        "    test_y = collatz_sequence(test_x)\n",
        "\n",
        "    prediction, actual = train_and_predict(model, train_x, train_y, np.array([test_x]), np.array([test_y]))\n",
        "\n",
        "\n",
        "\n",
        "    #save latest model\n",
        "    if random.randint(0,5) == 0:\n",
        "      print(\"saving...\")\n",
        "\n",
        "      # Print the results\n",
        "      print(f\"Test Example: n = {test_x}\")\n",
        "      print(f\"Predicted Stopping Time: {prediction*100000:.2f}\")\n",
        "      print(f\"Actual Stopping Time: {actual}\")\n",
        "      print(\"-\" * 40)\n",
        "\n",
        "      model.save('latest_model.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-CkUut4hARR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}