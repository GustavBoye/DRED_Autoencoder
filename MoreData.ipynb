{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0dyXyH5cpte7U7UwWEI0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavBoye/DRED_Autoencoder/blob/main/MoreData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAdt5Ppk1Ofb",
        "outputId": "880e52b4-97b6-4d58-d125-8523410a5c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS', 'AU', 'KGC', 'WPM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AG', 'NG', 'HMY', 'GMAB', 'NMM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CSIQ', 'MAG', 'CSCO', 'FSM', 'OR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['PYPL', 'HGBL', 'EW', 'BVN', 'RGLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['SEDG', 'FSLR', 'ENPH', 'JKS', 'RUN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NEE', 'CWEN', 'LNTH', 'CHKP', 'PANW']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MSFT', 'NVDA', 'AMD', 'INTC', 'GOOG']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['META', 'TSM', 'INTU', 'UMC', 'MU']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ORCL', 'ASML', 'DELL', 'TXN', 'QRVO']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['BIDU', 'SMCI', 'TSLA', 'ALB', 'LTBR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CAT', 'BWXT', 'BA', 'SIEGY', 'SQM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MA', 'MCD', 'AVXL', 'SRTS', 'HDSN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CCJ', 'AMZN', 'WELL', 'MPLX', 'TSE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ELD', 'UTHR', 'ABT', 'JNJ', 'BABA']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['JPM', 'SB', 'TER', 'ARKQ', 'BLX']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NRG', 'LIT', 'FLXS', 'BAESY', 'STE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IBM', 'KO', 'PEP', 'GS', 'V']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS', 'AU', 'KGC', 'WPM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AG', 'NG', 'HMY', 'GMAB', 'NMM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CSIQ', 'MAG', 'CSCO', 'FSM', 'OR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['PYPL', 'HGBL', 'EW', 'BVN', 'RGLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['SEDG', 'FSLR', 'ENPH', 'JKS', 'RUN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NEE', 'CWEN', 'LNTH', 'CHKP', 'PANW']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MSFT', 'NVDA', 'AMD', 'INTC', 'GOOG']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['META', 'TSM', 'INTU', 'UMC', 'MU']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ORCL', 'ASML', 'DELL', 'TXN', 'QRVO']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['BIDU', 'SMCI', 'TSLA', 'ALB', 'LTBR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CAT', 'BWXT', 'BA', 'SIEGY', 'SQM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MA', 'MCD', 'AVXL', 'SRTS', 'HDSN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CCJ', 'AMZN', 'WELL', 'MPLX', 'TSE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ELD', 'UTHR', 'ABT', 'JNJ', 'BABA']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['JPM', 'SB', 'TER', 'ARKQ', 'BLX']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NRG', 'LIT', 'FLXS', 'BAESY', 'STE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IBM', 'KO', 'PEP', 'GS', 'V']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS', 'AU', 'KGC', 'WPM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AG', 'NG', 'HMY', 'GMAB', 'NMM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CSIQ', 'MAG', 'CSCO', 'FSM', 'OR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['PYPL', 'HGBL', 'EW', 'BVN', 'RGLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['SEDG', 'FSLR', 'ENPH', 'JKS', 'RUN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NEE', 'CWEN', 'LNTH', 'CHKP', 'PANW']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MSFT', 'NVDA', 'AMD', 'INTC', 'GOOG']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['META', 'TSM', 'INTU', 'UMC', 'MU']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ORCL', 'ASML', 'DELL', 'TXN', 'QRVO']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['BIDU', 'SMCI', 'TSLA', 'ALB', 'LTBR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CAT', 'BWXT', 'BA', 'SIEGY', 'SQM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MA', 'MCD', 'AVXL', 'SRTS', 'HDSN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CCJ', 'AMZN', 'WELL', 'MPLX', 'TSE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ELD', 'UTHR', 'ABT', 'JNJ', 'BABA']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['JPM', 'SB', 'TER', 'ARKQ', 'BLX']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NRG', 'LIT', 'FLXS', 'BAESY', 'STE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IBM', 'KO', 'PEP', 'GS', 'V']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS', 'AU', 'KGC', 'WPM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AG', 'NG', 'HMY', 'GMAB', 'NMM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CSIQ', 'MAG', 'CSCO', 'FSM', 'OR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['PYPL', 'HGBL', 'EW', 'BVN', 'RGLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['SEDG', 'FSLR', 'ENPH', 'JKS', 'RUN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NEE', 'CWEN', 'LNTH', 'CHKP', 'PANW']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "3 Failed downloads:\n",
            "ERROR:yfinance:['PANW', 'CWEN', 'NEE']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MSFT', 'NVDA', 'AMD', 'INTC', 'GOOG']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['AMD', 'NVDA', 'MSFT', 'GOOG', 'INTC']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['META', 'TSM', 'INTU', 'UMC', 'MU']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['UMC', 'MU', 'TSM', 'META', 'INTU']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ORCL', 'ASML', 'DELL', 'TXN', 'QRVO']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['QRVO', 'ORCL', 'ASML', 'DELL', 'TXN']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['BIDU', 'SMCI', 'TSLA', 'ALB', 'LTBR']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['TSLA', 'BIDU', 'LTBR', 'ALB', 'SMCI']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CAT', 'BWXT', 'BA', 'SIEGY', 'SQM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  4 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['BWXT', 'SIEGY', 'CAT', 'SQM', 'BA']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['MA', 'MCD', 'AVXL', 'SRTS', 'HDSN']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['MA', 'HDSN', 'AVXL', 'SRTS', 'MCD']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['CCJ', 'AMZN', 'WELL', 'MPLX', 'TSE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['TSE', 'MPLX', 'CCJ', 'AMZN', 'WELL']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['ELD', 'UTHR', 'ABT', 'JNJ', 'BABA']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['UTHR', 'BABA', 'JNJ', 'ELD', 'ABT']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['JPM', 'SB', 'TER', 'ARKQ', 'BLX']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['ARKQ', 'JPM', 'BLX', 'TER', 'SB']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['NRG', 'LIT', 'FLXS', 'BAESY', 'STE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  4 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "[*********************100%***********************]  4 of 5 completedERROR:yfinance:['NRG', 'LIT', 'STE', 'FLXS', 'BAESY']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IBM', 'KO', 'PEP', 'GS', 'V']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['IBM', 'KO', 'PEP', 'V', 'GS']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
            "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
            "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1/4 for 16-day prediction...\n",
            "Epoch 1/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - loss: nan - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: nan - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: nan - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m60/89\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Helper function for normalization\n",
        "def normalize_min_max(data):\n",
        "    return (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n",
        "\n",
        "# Define input tickers\n",
        "input_tickers = [\n",
        "    'IAG', 'DRD', 'GOLD', 'NEM', 'GLD', 'AEM', 'PAAS', 'AU', 'KGC', 'WPM', 'AG', 'NG', 'HMY', 'GMAB', 'NMM', 'CSIQ', 'MAG', 'CSCO', 'FSM', 'OR', 'PYPL', 'HGBL', 'EW', 'BVN', 'RGLD',\n",
        "    'SEDG', 'FSLR', 'ENPH', 'JKS', 'RUN', 'NEE', 'CWEN', 'LNTH', 'CHKP', 'PANW',\n",
        "    'MSFT', 'NVDA', 'AMD', 'INTC', 'GOOG', 'META', 'TSM', 'INTU', 'UMC', 'MU', 'ORCL', 'ASML', 'DELL', 'TXN', 'QRVO', 'BIDU', 'SMCI',\n",
        "    'TSLA', 'ALB', 'LTBR', 'CAT', 'BWXT', 'BA', 'SIEGY', 'SQM', 'MA', 'MCD', 'AVXL', 'SRTS',\n",
        "    'HDSN', 'CCJ', 'AMZN', 'WELL', 'MPLX', 'TSE', 'ELD', 'UTHR', 'ABT', 'JNJ', 'BABA', 'JPM', 'SB', 'TER', 'ARKQ', 'BLX', 'NRG', 'LIT', 'FLXS', 'BAESY', 'STE', 'IBM', 'KO', 'PEP', 'GS', 'V'\n",
        "]\n",
        "\n",
        "import time\n",
        "import pandas as pd # Import pandas here\n",
        "import yfinance as yf\n",
        "\n",
        "def batch_download(tickers, start, end, batch_size=5, datatype='Close'):\n",
        "    all_data = {}\n",
        "    for i in range(0, len(tickers), batch_size):\n",
        "        batch_tickers = tickers[i:i + batch_size]\n",
        "        print(f\"Downloading data for: {batch_tickers}\")\n",
        "\n",
        "        # Try to download the data for this batch\n",
        "        try:\n",
        "            data = yf.download(batch_tickers, start=start, end=end, interval=\"1d\")[datatype]\n",
        "            all_data.update(data.to_dict())\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading data for {batch_tickers}: {e}\")\n",
        "            time.sleep(0.1)  # Wait for a bit before retrying if an error occurs\n",
        "\n",
        "        time.sleep(0.2)  # Sleep between batches to avoid hitting rate limits\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "# Fetch stock data in batches\n",
        "data = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='Close')\n",
        "data_volume = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='Volume')\n",
        "data_high = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='High')\n",
        "data_low = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='Low')\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = MinMaxScaler()\n",
        "scaler_vol = MinMaxScaler()\n",
        "scaler_high = MinMaxScaler()\n",
        "scaler_low = MinMaxScaler()\n",
        "\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled_vol = scaler_vol.fit_transform(data_volume)\n",
        "data_scaled_high = scaler_high.fit_transform(data_high)\n",
        "data_scaled_low = scaler_low.fit_transform(data_low)\n",
        "\n",
        "\n",
        "DAYS = 16\n",
        "HISTORY = 16\n",
        "\n",
        "\n",
        "# Function to create supervised learning dataset\n",
        "\n",
        "def create_input(data, vol, high, low, time_steps=0):\n",
        "    X=[]\n",
        "    data_to_insert_a = normalize_min_max(data[-time_steps:])\n",
        "    data_to_insert_b = normalize_min_max(vol[-time_steps:])\n",
        "    data_to_insert_c = normalize_min_max(high[-time_steps:])\n",
        "    data_to_insert_d = normalize_min_max(low[-time_steps:])\n",
        "    data_to_insert = np.concatenate([data_to_insert_a, data_to_insert_b,data_to_insert_c,data_to_insert_d], axis=1)\n",
        "    X.append(data_to_insert)\n",
        "\n",
        "\n",
        "    # Convert to a numpy array and return\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "\n",
        "def create_dataset(data, vol, high, low, time_steps=0, future_steps=0, threshold=0.1, inverted=False):\n",
        "    if inverted:\n",
        "      data = 1-data\n",
        "      high = 1-high\n",
        "      low = 1-low\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps - future_steps):\n",
        "        # Normalize and prepare input data\n",
        "        data_to_insert_a = normalize_min_max(data[i:i + time_steps])\n",
        "        data_to_insert_b = normalize_min_max(vol[i:i + time_steps])\n",
        "        data_to_insert_c = normalize_min_max(high[-time_steps:])\n",
        "        data_to_insert_d = normalize_min_max(low[-time_steps:])\n",
        "        data_to_insert = np.concatenate([data_to_insert_a, data_to_insert_b,data_to_insert_c,data_to_insert_d], axis=1)\n",
        "        X.append(data_to_insert)\n",
        "\n",
        "        future_prices = data[i + time_steps:i + time_steps + future_steps]\n",
        "        current_price = data[i + time_steps - 1]\n",
        "        future_average_price = np.mean(future_prices, axis=0)\n",
        "        target = future_average_price - current_price\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# Prepare dataset (200-day version)\n",
        "X_s, y_s = create_dataset(data_scaled, data_scaled_vol, data_scaled_high, data_scaled_low, time_steps=HISTORY, future_steps=DAYS)\n",
        "X_inv_s, y_inv_s = create_dataset(data_scaled, data_scaled_vol, data_scaled_high, data_scaled_low, time_steps=HISTORY, future_steps=DAYS, inverted=True)\n",
        "X_combined_s = np.concatenate((X_s, X_inv_s), axis=0)\n",
        "y_combined_s = np.concatenate((y_s, y_inv_s), axis=0)\n",
        "input_data = create_input(data_scaled, data_scaled_vol, data_scaled_high, data_scaled_low, time_steps=HISTORY)\n",
        "\n",
        "\n",
        "def build_model(shape1, shape2, version):\n",
        "    input_layer = tf.keras.layers.Input(shape=(shape1, shape2))\n",
        "\n",
        "    if version == 0:\n",
        "      x = tf.keras.layers.SpatialDropout1D(0.2)(input_layer)\n",
        "      x = tf.keras.layers.Conv1D(64, 3, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(64, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)  # ✅ Add Transformer attention\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(512, activation='gelu')(x)\n",
        "      dense1 = tf.keras.layers.Dropout(0.2)(dense1)\n",
        "      dense2 = tf.keras.layers.Dense(512, activation='gelu')(dense1)\n",
        "      dense = dense1+dense2\n",
        "\n",
        "      output = tf.keras.layers.Dense(len(input_tickers))(dense)\n",
        "    elif version == 1:\n",
        "      x = tf.keras.layers.SpatialDropout1D(0.6)(input_layer)\n",
        "      x = tf.keras.layers.GaussianNoise(0.2)(x)\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)  # ✅ Add Transformer attention\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(256, activation='gelu')(x)\n",
        "      dense1 = tf.keras.layers.Dropout(0.4)(dense1)\n",
        "      dense2 = tf.keras.layers.Dense(256, activation='gelu')(dense1)\n",
        "      dense = dense1+dense2\n",
        "\n",
        "      output = tf.keras.layers.Dense(len(input_tickers))(dense)\n",
        "    elif version == 2:\n",
        "      x = tf.keras.layers.SpatialDropout1D(0.2)(input_layer)\n",
        "      x = tf.keras.layers.GaussianNoise(0.1)(x)\n",
        "      x = tf.keras.layers.Conv1D(64, 3, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 5, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=32)(x, x)  # ✅ Add Transformer attention\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=32)(x, x)  # ✅ Add Transformer attention\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(256, activation='gelu')(x)\n",
        "      dense1 = tf.keras.layers.Dropout(0.4)(dense1)\n",
        "      dense2 = tf.keras.layers.Dense(256, activation='gelu')(dense1)\n",
        "      dense = dense1+dense2\n",
        "\n",
        "      output = tf.keras.layers.Dense(len(input_tickers))(dense)\n",
        "\n",
        "    elif version == 3:\n",
        "      x = tf.keras.layers.SpatialDropout1D(0.2)(input_layer)\n",
        "      x = tf.keras.layers.GaussianNoise(0.1)(x)\n",
        "      x = tf.keras.layers.Conv1D(64, 3, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(256, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(256, activation='gelu')(x)\n",
        "      dense2 = tf.keras.layers.Dense(256, activation='gelu')(dense1)\n",
        "      dense = dense1+dense2\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(256, activation='gelu')(dense)\n",
        "      dense2 = tf.keras.layers.Dense(256, activation='gelu')(dense1)\n",
        "      F = dense1+dense2\n",
        "\n",
        "      output = tf.keras.layers.Dense(len(input_tickers))(F)\n",
        "\n",
        "    elif version == 4:\n",
        "      x = tf.keras.layers.SpatialDropout1D(0.3)(input_layer)\n",
        "      x = tf.keras.layers.GaussianNoise(0.02)(x)\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.006))(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(128, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(256, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Conv1D(256, 3, strides=2, padding=\"same\")(x)\n",
        "      x = tf.keras.layers.LayerNormalization()(x)\n",
        "      x = tf.keras.layers.Activation('gelu')(x)\n",
        "\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(256, activation='gelu')(x)\n",
        "      dense2 = tf.keras.layers.Dense(256, activation='gelu')(dense1)\n",
        "      dense = dense1+dense2\n",
        "\n",
        "      dense1 = tf.keras.layers.Dense(256, activation='gelu')(dense)\n",
        "      dense2 = tf.keras.layers.Dense(256, activation='gelu')(dense1)\n",
        "      F = dense1+dense2\n",
        "\n",
        "      output = tf.keras.layers.Dense(len(input_tickers))(F)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Training setup\n",
        "num_models = 4\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=32, min_delta=1e-4, restore_best_weights=True, mode='min', verbose=1)\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=16, verbose=1)\n",
        "\n",
        "import random\n",
        "# Train the ensemble (200-day version)\n",
        "ensemble = []\n",
        "for i in range(num_models):\n",
        "    print(f\"Training model {i+1}/{num_models} for {DAYS}-day prediction...\")\n",
        "    model = build_model(X_combined_s.shape[1], X_combined_s.shape[2], i)\n",
        "    optimizer = tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-5)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    model.fit(X_combined_s, y_combined_s, epochs=20, batch_size=32, validation_split=0.3, verbose=1, callbacks=[early_stopping, lr_scheduler])\n",
        "    ensemble.append(model)\n",
        "\n",
        "# Predictions (200-day version)\n",
        "predictions = {ticker: [] for ticker in input_tickers}\n",
        "for idx, ticker in enumerate(input_tickers):\n",
        "    predictions[ticker] = np.mean([m(input_data).numpy()[:, idx] for m in ensemble], axis=0)\n",
        "\n",
        "# Plot predictions\n",
        "fig, ax = plt.subplots(figsize=(18, 10))\n",
        "tickers_range = np.arange(len(input_tickers))\n",
        "pred_days = np.array([predictions[ticker] for ticker in input_tickers]).flatten()\n",
        "ax.bar(tickers_range, pred_days, color='blue', width=0.6, label='200-Day Prediction')\n",
        "\n",
        "ax.set_title(\"200-Day Predictions for All Tickers\", fontsize=16)\n",
        "ax.set_xlabel(\"Tickers\", fontsize=14)\n",
        "ax.set_ylabel(\"Predicted Change\", fontsize=14)\n",
        "ax.set_xticks(tickers_range)\n",
        "ax.set_xticklabels(input_tickers, rotation=45, fontsize=10)\n",
        "ax.legend(title=\"Prediction Length\", fontsize=10)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Convert predictions dictionary to DataFrame\n",
        "predictions_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['{DAYS}-Day Prediction'])\n",
        "\n",
        "# Save as CSV\n",
        "predictions_df.to_csv(f\"predictions_{DAYS}.csv\")\n",
        "\n",
        "# Download in Colab\n",
        "from google.colab import files\n",
        "files.download(f\"predictions_{DAYS}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Helper function for normalization\n",
        "def normalize_min_max(data):\n",
        "    return (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n",
        "\n",
        "# Define input tickers\n",
        "input_tickers = [\n",
        "    'IAG', 'DRD', 'GOLD', 'NEM', 'GLD', 'AEM', 'PAAS', 'AU', 'KGC', 'WPM', 'AG', 'NG', 'HMY', 'GMAB', 'NMM', 'CSIQ', 'MAG', 'CSCO', 'FSM', 'OR', 'PYPL', 'HGBL', 'EW', 'BVN', 'RGLD',\n",
        "    'SEDG', 'FSLR', 'ENPH', 'JKS', 'RUN', 'NEE', 'CWEN', 'LNTH', 'CHKP', 'PANW',\n",
        "    'MSFT', 'NVDA', 'AMD', 'INTC', 'GOOG', 'META', 'TSM', 'INTU', 'UMC', 'MU', 'ORCL', 'ASML', 'DELL', 'TXN', 'QRVO', 'BIDU', 'SMCI',\n",
        "    'TSLA', 'ALB', 'LTBR', 'CAT', 'BWXT', 'BA', 'SIEGY', 'SQM', 'MA', 'MCD', 'AVXL', 'SRTS',\n",
        "    'HDSN', 'CCJ', 'AMZN', 'WELL', 'MPLX', 'TSE', 'ELD', 'UTHR', 'ABT', 'JNJ', 'BABA', 'JPM', 'SB', 'TER', 'ARKQ', 'BLX', 'NRG', 'LIT', 'FLXS', 'BAESY', 'STE', 'IBM', 'KO', 'PEP', 'GS', 'V'\n",
        "]\n",
        "\n",
        "import time\n",
        "import pandas as pd # Import pandas here\n",
        "import yfinance as yf\n",
        "\n",
        "def batch_download(tickers, start, end, batch_size=5, datatype='Close'):\n",
        "    all_data = {}\n",
        "    for i in range(0, len(tickers), batch_size):\n",
        "        batch_tickers = tickers[i:i + batch_size]\n",
        "        print(f\"Downloading data for: {batch_tickers}\")\n",
        "\n",
        "        # Try to download the data for this batch\n",
        "        try:\n",
        "            data = yf.download(batch_tickers, start=start, end=end, interval=\"1d\")[datatype]\n",
        "            all_data.update(data.to_dict())\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading data for {batch_tickers}: {e}\")\n",
        "            time.sleep(0.2)  # Wait for a bit before retrying if an error occurs\n",
        "\n",
        "        time.sleep(0.5)  # Sleep between batches to avoid hitting rate limits\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "# Fetch stock data in batches\n",
        "data = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='Close')\n",
        "data_volume = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='Volume')\n",
        "data_high = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='High')\n",
        "data_low = batch_download(input_tickers, start=\"2017-01-01\", end=\"2025-02-27\", datatype='Low')\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = MinMaxScaler()\n",
        "scaler_vol = MinMaxScaler()\n",
        "scaler_high = MinMaxScaler()\n",
        "scaler_low = MinMaxScaler()\n",
        "\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled_vol = scaler_vol.fit_transform(data_volume)\n",
        "data_scaled_high = scaler_high.fit_transform(data_high)\n",
        "data_scaled_low = scaler_low.fit_transform(data_low)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0qdTrtBISTx",
        "outputId": "08e8800a-9b61-44fa-a5b7-51b41f028fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*******************   40%                       ]  2 of 5 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[**********************80%*************          ]  4 of 5 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[**********************80%*************          ]  4 of 5 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['IAG', 'DRD', 'GOLD', 'NEM', 'GLD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for: ['AEM', 'PAAS']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IoGSv5fqKKzX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}